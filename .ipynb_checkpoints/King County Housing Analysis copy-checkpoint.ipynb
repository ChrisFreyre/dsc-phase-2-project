{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19c240de",
   "metadata": {},
   "source": [
    "<h1 align=center>King County Housing Analysis</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf9e73d",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8834a40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats as stats\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from math import sqrt\n",
    "from random import gauss\n",
    "from mpl_toolkits import mplot3d\n",
    "import sklearn.metrics as metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124b676",
   "metadata": {},
   "source": [
    " <h2 align=center>Understanding the Data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0101835e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/kc_house_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xh/3k7868c90fn2gr8g562tzd500000gn/T/ipykernel_23333/665712973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# IMPORTING THE DATA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/kc_house_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/kc_house_data.csv'"
     ]
    }
   ],
   "source": [
    "# IMPORTING THE DATA \n",
    "df = pd.read_csv('../data/kc_house_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d134e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAPE OF DATA FRAME\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d35fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA FRAME\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d4c387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b735795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIQUE YEAR FOR THIS DATA FRAME\n",
    "\n",
    "df['year'] = pd.DatetimeIndex(df['date']).year\n",
    "df['year'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371d3f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = lambda x : '{:.0f}'.format(x) if int(x) == x else '{:,.2f}'.format(x)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45782ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d3d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT DATA HISTOGRAM\n",
    "df.hist(figsize=(15,15), edgecolor = 'black');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fd8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEATMAP FOR CORRELATION DATAFRAME\n",
    "\n",
    "corr = df.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 20))\n",
    "\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', vmax=1, center=0,\n",
    "            square=True, linewidths=.5,annot=True, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5656b9",
   "metadata": {},
   "source": [
    " <h2 align=center>Data Cleaning</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6563fa37",
   "metadata": {},
   "source": [
    "**Check List:**\n",
    "\n",
    "* Missing values\n",
    "* Data type conversions\n",
    "* Checking for and removing multicollinearity\n",
    "* Normalizing our numeric data\n",
    "* Converting categorical data to numeric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0902761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING FOR DUPLICATES\n",
    "\n",
    "len(set(df['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c07d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING DUPLICATES IN ID COLUMN\n",
    "\n",
    "df.drop_duplicates(subset='id', inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3344f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING FOR OBJECTS IN SQFT_BASEMENT\n",
    "\n",
    "df['sqft_basement'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8a1a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE VALUES IN 'SQFT_BASEMENT' == TO '?' FOR '0'\n",
    "\n",
    "df.loc[df['sqft_basement'] == '?','sqft_basement'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce47885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECKING 'YR_RENOVATED' \n",
    "\n",
    "df['yr_renovated'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4778ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGING 'YR_RENOVATED' FOR 'INT64'\n",
    "\n",
    "df['yr_renovated'] = df['yr_renovated'].astype('Int64')\n",
    "df['yr_renovated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2147386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK FOR NULL VALUES\n",
    "\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e47c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'WATERFRONT' VALUES\n",
    "\n",
    "df['waterfront'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178acf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'VIEW' VALUES\n",
    "\n",
    "df['view'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5721e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'GRADE' VALUES\n",
    "\n",
    "df['grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc3036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'condition' VALUES\n",
    "\n",
    "df['condition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL NAN IN 'YR_RENOVATED' WITH '0'\n",
    "\n",
    "df['yr_renovated'] = df['yr_renovated'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e5f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING COLUMNS\n",
    "\n",
    "df.drop(columns = ['id', 'date', 'view', 'sqft_above', 'sqft_basement', 'yr_renovated', \n",
    "                   'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f3c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93719f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fb5a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEATMAP FOR CORRELATION DATAFRAME\n",
    "\n",
    "corr = df.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 20))\n",
    "\n",
    "sns.heatmap(corr, mask=mask, cmap='coolwarm', vmax=1, center=0,\n",
    "            square=True, linewidths=.5,annot=True, cbar_kws={\"shrink\": .5});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799abd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad92058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTING RELATIONSHIP BETWEEN PRICE (BEDROOM, BATHROOM AND SQFT_LINVING)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(18, 6))\n",
    "for idx, channel in enumerate(['bedrooms', 'bathrooms', 'sqft_living']):\n",
    "    df.plot(kind='scatter', x=channel, y='price', ax=axs[idx], label=channel)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff654809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTING RELATIONSHIP BETWEEN PRICE (SQFT_LOT, FLOORS AND WATERFRONT)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(18, 6))\n",
    "for idx, channel in enumerate(['sqft_lot', 'floors', 'waterfront']):\n",
    "    df.plot(kind='scatter', x=channel, y='price', ax=axs[idx], label=channel)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cc16fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTING RELATIONSHIP BETWEEN PRICE (CONDITION, GRADE AND YR_BUILT)\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(18, 6))\n",
    "for idx, channel in enumerate(['condition', 'grade', 'yr_built']):\n",
    "    df.plot(kind='scatter', x=channel, y='price', ax=axs[idx], label=channel)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01cc824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING 'WATERFRONT'\n",
    "\n",
    "df.drop(columns = ['waterfront'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f707797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WE CAN SEE 33 BEDROOMS AND OTHER ANOMALIES THAT WILL BE CONSIDER OUTLIERS\n",
    "\n",
    "pd.options.display.float_format = lambda x : '{:.0f}'.format(x) if int(x) == x else '{:,.2f}'.format(x)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5fbc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTAINING Z-SCORES  \n",
    "zscore = np.abs(stats.zscore(df))\n",
    "zscore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f32647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DETECTING OUTLIERS WITH OVER 3 STANDARD DEVIATION FROM THE MEAN IN DATAFRAME\n",
    "\n",
    "outliers = df[(np.abs(zscore) > 3).any(1)]\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f625801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OUTLIER DESCRIBE TABLE EXAMPLE: 33 BEDROOMS \n",
    "\n",
    "pd.options.display.float_format = lambda x : '{:.0f}'.format(x) if int(x) == x else '{:,.2f}'.format(x)\n",
    "outliers.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f57c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OBTAINING ALL DATA THAT IS IN BETWEEN 3 STANDAR DEVIATION OF THE MEAN, ELIMINATING OUTLIERS\n",
    "\n",
    "df = df[(zscore < 3).all(axis=1)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6effdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZING OUR NUMERIC DATA FOR DESCRIBE FUNCTION\n",
    "\n",
    "pd.options.display.float_format = lambda x : '{:.0f}'.format(x) if int(x) == x else '{:,.2f}'.format(x)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c96de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RE-PLOTING RELATIONSHIP BETWEEN PRICE (BEDROOM, BATHROOM AND SQFT_LINVING) AFTER ELIMINATING OUTLIERS\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(18, 6))\n",
    "for idx, channel in enumerate(['bedrooms', 'bathrooms', 'sqft_living']):\n",
    "    df.plot(kind='scatter', x=channel, y='price', ax=axs[idx], label=channel)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e78f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RE-PLOTING RELATIONSHIP BETWEEN PRICE (SQFT_LOT AND FLOORS) AFTER ELIMINATING OUTLIERS\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, sharey=True, figsize=(18, 6))\n",
    "for idx, channel in enumerate(['sqft_lot', 'floors']):\n",
    "    df.plot(kind='scatter', x=channel, y='price', ax=axs[idx], label=channel)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c735c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RE-PLOTING RELATIONSHIP BETWEEN PRICE (CONDITION, GRADE AND YR_BUILT) AFTER ELIMINATING OUTLIERS\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, sharey=True, figsize=(18, 6))\n",
    "for idx, channel in enumerate(['condition', 'grade', 'yr_built']):\n",
    "    df.plot(kind='scatter', x=channel, y='price', ax=axs[idx], label=channel)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d08efe7",
   "metadata": {},
   "source": [
    " <h2 align=center>Baseline Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d8d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING COLUMNS\n",
    "df.drop(columns = ['floors', 'yr_built'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3540ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3131bc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA SEPARATION INTO PREDITORS AND TARGET\n",
    "\n",
    "house_preds = df.drop('price', axis=1)\n",
    "house_target = df['price']\n",
    "house_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fad7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INDIPENDENT VARIABLES \n",
    "\n",
    "predictors = sm.add_constant(house_preds)\n",
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec5b4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASELINE MODEL \n",
    "\n",
    "baseline_model = sm.OLS(house_target, predictors).fit ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cea9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb70cb6",
   "metadata": {},
   "source": [
    "\n",
    "**This means that 59.5% of the variation in the dependent variable is explained by variation in the explanatory variable. Meaning that we still have 40.5% of the variation is unexplained by the model.** \n",
    "\n",
    "**So let's get back to it to refine our model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597af687",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = baseline_model.resid\n",
    "sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True, )    \n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055e6cc",
   "metadata": {},
   "source": [
    "# Assumption of regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4281cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation 'Price' vs all variables\n",
    "\n",
    "data_corrs = df.corr()['price'].map(abs).sort_values(ascending=False)\n",
    "data_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bc5f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5457d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTING RELATIONSHIP BETWEEN PRICE (BEDROOM, BATHROOM, SQFT_LINVING AND GRADE) AFTER ELIMINATING OUTLIERS\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, sharey=True, figsize=(18, 6))\n",
    "for idx, channel in enumerate(['bedrooms', 'bathrooms', 'sqft_living', 'grade']):\n",
    "    df.plot(kind='scatter', x=channel, y='price', ax=axs[idx], label=channel)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160f7953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Plots for 'Price vs Sqft_living'\n",
    "\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "fig = sm.graphics.plot_regress_exog(baseline_model, \"sqft_living\", fig=fig)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f894b2",
   "metadata": {},
   "source": [
    "Now we see that is a strong correlation meaning that has a homoscedasticity between price and sqft_living is following a great line. Also we can see that bedrooms, bathrooms and grade are categorical so we will need to create dummy variables for each so we can have a more accurate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5724f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION OF BATHROOMS COLUMNS\n",
    "\n",
    "df = df[['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "       'condition', 'grade']] # deleted foors and yr_built\n",
    "df.loc[df['bathrooms'] <= 1,'bathrooms'] = 1\n",
    "df.loc[(df['bathrooms'] > 1) & (df['bathrooms'] <= 2),'bathrooms'] = 2\n",
    "df.loc[(df['bathrooms'] > 2) & (df['bathrooms'] <= 3),'bathrooms'] = 3\n",
    "df.loc[(df['bathrooms'] > 3) & (df['bathrooms'] <= 4),'bathrooms'] = 4\n",
    "df.loc[(df['bathrooms'] > 4) & (df['bathrooms'] <= 5),'bathrooms'] = 5\n",
    "df.loc[(df['bathrooms'] > 5) & (df['bathrooms'] <= 6),'bathrooms'] = 6\n",
    "df.loc[(df['bathrooms'] > 6) & (df['bathrooms'] <= 7),'bathrooms'] = 7\n",
    "df.loc[(df['bathrooms'] > 7) & (df['bathrooms'] <= 8),'bathrooms'] = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebce04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING A COPY OF DATA FRAME BEFORE MODIFIYING WITH DUMMIES FOR FUTURE MODELS\n",
    "\n",
    "df_model = df.copy()\n",
    "df_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5633c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(df, figsize=(18,12));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ca3664",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91446ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGING 'BATHROOMS' TO INT64\n",
    "\n",
    "df['bathrooms'] = df['bathrooms'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288063b",
   "metadata": {},
   "source": [
    " <h3 align=center>Data with Dummies</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee42df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING DUMMIES FOR \"GRADE\", \"BEDROOMS\" AND \"BATHROOMS\" \n",
    "\n",
    "df_dummies = pd.get_dummies(df, columns=['grade', 'bedrooms', 'bathrooms'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ecec52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edab3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns\n",
    "\n",
    "df_dummies.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d066d44",
   "metadata": {},
   "source": [
    "# Model 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a075f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'price'\n",
    "x_cols = ['sqft_living', 'sqft_lot', 'condition', \n",
    "       'grade_5', 'grade_6', 'grade_7', 'grade_8', 'grade_9', 'grade_10',\n",
    "       'grade_11', 'bedrooms_1', 'bedrooms_2', 'bedrooms_3', 'bedrooms_4',\n",
    "       'bedrooms_5', 'bedrooms_6', 'bathrooms_1', 'bathrooms_2', 'bathrooms_3',\n",
    "       'bathrooms_4', 'bathrooms_5']\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model_2 = ols(formula=formula, data=df_dummies).fit()\n",
    "\n",
    "\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f39c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model_2.resid\n",
    "sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True, )    \n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f0d1c1",
   "metadata": {},
   "source": [
    " <h3 align=center>Validation Model 2</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91833692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECTING 'X' AND 'Y' VALUES FROM 'DATA_LOG' FOR TRAIN-TEST SPLIT\n",
    "X = df_dummies.drop('price', axis=1)\n",
    "y = df_dummies['price']\n",
    "\n",
    "df_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1425827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN-TEST SPLIT0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY AND MODEL THE TRAIN-TEST SET\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "\n",
    "#CALCULATE TRAINING AND TEST RESIDUALS\n",
    "train_residuals = y_hat_train - y_train\n",
    "test_residuals = y_hat_test - y_test\n",
    "\n",
    "\n",
    "# CALCUALTE MEAN SQUARE ERROR\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error:', train_mse)\n",
    "print('Test Mean Squared Error:', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION RESULTS \n",
    "mse = make_scorer(mean_squared_error)\n",
    "cv_5_results = cross_val_score(linreg, X, y, cv=5, scoring=mse)\n",
    "cv_5_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd0ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTING PRICE\n",
    "sns.distplot(df_dummies['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef369000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTING SQFT_LIVING\n",
    "sns.distplot(df_dummies['sqft_living'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0c7be0",
   "metadata": {},
   "source": [
    "<h3 align=center>Data Log Transformation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6568780d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PERFORM DATA LOG TRANSFORMATION \n",
    "\n",
    "data_log = pd.DataFrame([])\n",
    "   \n",
    "data_log['price_log'] = np.log(df_model['price'])\n",
    "data_log['bedrooms'] = (df_model['bedrooms'])\n",
    "data_log['bathrooms'] = (df_model['bathrooms'])\n",
    "data_log['sqft_living_log'] = np.log(df_model['sqft_living'])\n",
    "data_log['sqft_lot_log'] = np.log(df_model['sqft_lot'])\n",
    "data_log['condition'] = (df_model['condition'])\n",
    "data_log['grade'] = (df_model['grade'])\n",
    "   \n",
    "data_log.hist(figsize  = [18,8]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb140f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGING 'BATHROOMS' TO INT64\n",
    "\n",
    "data_log['bathrooms'] = data_log['bathrooms'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f2c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDING DUMMIES FOR \"GRADE\", \"BEDROOMS\" AND \"BATHROOMS\" \n",
    "\n",
    "data_log = pd.get_dummies(data_log, columns=['grade', 'bedrooms', 'bathrooms', 'condition'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7ed65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38371a1",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb1786",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_log.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251b599d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome = 'price_log'\n",
    "x_cols = ['sqft_living_log', 'sqft_lot_log', 'grade_5',\n",
    "       'grade_6', 'grade_7', 'grade_8', 'grade_9', 'grade_10', 'grade_11',\n",
    "       'bedrooms_1', 'bedrooms_2', 'bedrooms_3', 'bedrooms_4', 'bedrooms_5',\n",
    "       'bedrooms_6', 'bathrooms_1', 'bathrooms_2', 'bathrooms_3',\n",
    "       'bathrooms_4', 'bathrooms_5', 'condition_2', 'condition_3', 'condition_4',\n",
    "       'condition_5']\n",
    "predictors = '+'.join(x_cols)\n",
    "formula = outcome + '~' + predictors\n",
    "model_3 = ols(formula=formula, data=data_log).fit()\n",
    "\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e26b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals = model_3.resid\n",
    "sm.graphics.qqplot(residuals, dist=stats.norm, line='45', fit=True, )    \n",
    "plt.show;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1deca",
   "metadata": {},
   "source": [
    " <h3 align=center>Validation Model 3</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6daed5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECTING 'X' AND 'Y' VALUES FROM 'DATA_LOG' FOR TRAIN-TEST SPLIT\n",
    "\n",
    "X = data_log.drop('price_log', axis=1)\n",
    "y = data_log['price_log']\n",
    "\n",
    "data_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97278e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN-TEST SPLIT\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b929e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# APPLY AND MODEL THE TRAIN-TEST SET\n",
    "linreg = LinearRegression()\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train = linreg.predict(X_train)\n",
    "y_hat_test = linreg.predict(X_test)\n",
    "\n",
    "\n",
    "#CALCULATE TRAINING AND TEST RESIDUALS\n",
    "train_residuals = y_hat_train - y_train\n",
    "test_residuals = y_hat_test - y_test\n",
    "\n",
    "\n",
    "# CALCUALTE MEAN SQUARE ERROR\n",
    "train_mse = mean_squared_error(y_train, y_hat_train)\n",
    "test_mse = mean_squared_error(y_test, y_hat_test)\n",
    "print('Train Mean Squared Error:', train_mse)\n",
    "print('Test Mean Squared Error:', test_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce59d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS VALIDATION RESULTS \n",
    "mse = make_scorer(mean_squared_error)\n",
    "cv_5_results = cross_val_score(linreg, X, y, cv=5, scoring=mse)\n",
    "cv_5_results.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
